{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5e44534",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size = (3, 3)  # 3 Zeilen, 3 Spalten\n",
    "\n",
    "# Plätze mit Namen und Koordinaten\n",
    "places = {\n",
    "    'R': (0, 0),\n",
    "    'G': (1, 0),\n",
    "    'Y': (0, 2),\n",
    "    'B': (1, 2)\n",
    "}\n",
    "\n",
    "# Mauern als Liste von Paaren (von Feld zu Feld)\n",
    "walls = [\n",
    "    ((0, 2), (1, 2)),  # Mauer zwischen (0,2) und (1,2)\n",
    "    ((2, 0), (2, 1))   # Mauer zwischen (2,0) und (2,1)\n",
    "]\n",
    "\n",
    "# Prüfe ob zwischen den Feldern eine Mauer ist\n",
    "# Gib True zurück wenn Bewegung nicht möglich ist\n",
    "def is_blocked(from_pos, to_pos, walls):\n",
    "    return (from_pos, to_pos) in walls or (to_pos, from_pos) in walls\n",
    "\n",
    "passenger_locations = list(places.keys()) + ['IN_TAXI']\n",
    "destinations = list(places.keys())\n",
    "\n",
    "# Aufbau der Zustände als Liste von Tupeln\n",
    "states = []\n",
    "for taxi_x in range(grid_size[0]):\n",
    "    for taxi_y in range(grid_size[1]):\n",
    "        for passenger in passenger_locations:\n",
    "            for destination in destinations:\n",
    "                # Hier Tupel für jeden Zustand erstellen\n",
    "                states.append((taxi_x, taxi_y, passenger, destination))\n",
    "\n",
    "# Actionen definieren\n",
    "actions = ['south', 'north', 'east', 'west', 'pickup', 'dropoff']\n",
    "\n",
    "# Definition der Bewegung \n",
    "move = {\n",
    "    'south': (1, 0),\n",
    "    'north': (-1, 0),\n",
    "    'east': (0, 1),\n",
    "    'west': (0, -1)\n",
    "}\n",
    "\n",
    "# Dictionary für die Dynamik: transitions[state][action] = (next_state, reward, done)\n",
    "#--------------------------------------------------------------------------------\n",
    "transitions = {}\n",
    "for state in states:\n",
    "    #print(f\"Berechne Übergänge für Zustand: {state}\")\n",
    "    #input(\"Drücke Enter, um fortzufahren...\")\n",
    "    transitions[state] = {}\n",
    "    taxi_x, taxi_y, passenger_loc, destination = state\n",
    "    for action in actions:\n",
    "        #print(f\"  Aktion: {action}\")\n",
    "        # Initialwerte\n",
    "        next_state = state\n",
    "        reward = -1  # Standard-Strafpunkt für jeden Schritt\n",
    "        done = False\n",
    "\n",
    "        # Prüfe ob wir einen Bewegungsbefehl machen\n",
    "        if action in move:\n",
    "            # Bewegung\n",
    "            dx, dy = move[action]\n",
    "            new_x, new_y = taxi_x + dx, taxi_y + dy\n",
    "            # Prüfe ob neue Position innerhalb des 3x3 Grids liegt\n",
    "            if 0 <= new_x < grid_size[0] and 0 <= new_y < grid_size[1]:\n",
    "                # Prüfe ob Bewegung durch Mauer blockiert ist\n",
    "                if is_blocked((taxi_x, taxi_y), (new_x, new_y), walls) == True:\n",
    "                    # Bewegung durch Mauer blockiert\n",
    "                    next_state = (taxi_x, taxi_y, passenger_loc, destination)\n",
    "                else:\n",
    "                    # Bewegung erlaubt\n",
    "                    next_state = (new_x, new_y, passenger_loc, destination)\n",
    "            else:\n",
    "                # Bewegung außerhalb des Grids\n",
    "                next_state = (taxi_x, taxi_y, passenger_loc, destination)\n",
    "        elif action == 'pickup':\n",
    "            # Passagier aufnehmen\n",
    "            if (passenger_loc != 'IN_TAXI' \\\n",
    "                and (taxi_x, taxi_y) == places[passenger_loc]):\n",
    "                reward = 10  # Belohnung für erfolgreichen Pickup\n",
    "                next_state = (taxi_x, taxi_y, 'IN_TAXI', destination)\n",
    "            else:\n",
    "                reward = -10  # Strafpunkt für fehlerhaften Pickup\n",
    "        elif action == 'dropoff':\n",
    "            # Passagier absetzen\n",
    "            if (passenger_loc == 'IN_TAXI' \\\n",
    "                and (taxi_x, taxi_y) == places[destination]):\n",
    "                next_state = (taxi_x, taxi_y, destination, destination)\n",
    "                reward = 20  # Belohnung für erfolgreichen Dropoff\n",
    "                done = True\n",
    "            else:\n",
    "                reward = -10  # Strafpunkt für fehlerhaften Dropoff\n",
    "        \n",
    "        # Praktisch Martrix: Transitions_(s,a) = (s', r, done)\n",
    "        transitions[state][action] = (next_state, reward, done)\n",
    "        #print(f\"    Nächster Zustand: {next_state}, Belohnung: {reward}, Fertig: {done}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e6e821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Konvergenz nach 10 Iterationen\n"
     ]
    }
   ],
   "source": [
    "def value_iteration(states, transitions, gamma=0.9, epsilon=1e-6, max_iterations=1000):\n",
    "    # Initialisiere V(s) = 0 für alle 180 Zustände als Dictionary\n",
    "    V = {state: 0.0 for state in states}\n",
    "    \n",
    "    for iteration in range(max_iterations):\n",
    "        V_new = {}\n",
    "        max_delta = 0\n",
    "        \n",
    "        for state in states:\n",
    "            # Überspringe Terminalzustände (wo Passagier bereits am Ziel ist)\n",
    "            passenger_loc, destination = state[2], state[3] \n",
    "            if passenger_loc == destination and passenger_loc != 'IN_TAXI':\n",
    "                V_new[state] = 0\n",
    "                # Ausstieg aus der Schleife\n",
    "                continue\n",
    "                \n",
    "            best_value = -float('inf')\n",
    "            # Hier Maximierung über Aktionen\n",
    "            for action in actions:\n",
    "                next_state, reward, done = transitions[state][action]\n",
    "                \n",
    "                # Wenn Terminalzustand erreicht, future_value = 0\n",
    "                if done == True:\n",
    "                    future_value = 0\n",
    "                else:\n",
    "                    # Im ersten Aufruf immer 0 da V(s) = 0 initialisiert\n",
    "                    future_value = V[next_state]\n",
    "                \n",
    "                # Q(s,a) = R(s,a,s') + γ * V(s')\n",
    "                action_value = reward + gamma * future_value\n",
    "                \n",
    "                if action_value > best_value:\n",
    "                    best_value = action_value\n",
    "            \n",
    "            V_new[state] = best_value\n",
    "            max_delta = max(max_delta, abs(V_new[state] - V[state]))\n",
    "        \n",
    "        V = V_new\n",
    "        \n",
    "        # Abbruch Bedingung formulieren\n",
    "        if max_delta < epsilon:\n",
    "            print(f\"Konvergenz nach {iteration + 1} Iterationen\")\n",
    "            break\n",
    "    return V\n",
    "\n",
    "# Beispielaufruf der Value Iteration\n",
    "V = value_iteration(states, transitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "930b7412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zustand: (2, 1, 'B', 'Y'), Aktion: north, Belohnung: -1\n",
      "Zustand: (1, 1, 'B', 'Y'), Aktion: east, Belohnung: -1\n",
      "Zustand: (1, 2, 'B', 'Y'), Aktion: pickup, Belohnung: 10\n",
      "Zustand: (1, 2, 'IN_TAXI', 'Y'), Aktion: west, Belohnung: -1\n",
      "Zustand: (1, 1, 'IN_TAXI', 'Y'), Aktion: north, Belohnung: -1\n",
      "Zustand: (0, 1, 'IN_TAXI', 'Y'), Aktion: east, Belohnung: -1\n",
      "Zustand: (0, 2, 'IN_TAXI', 'Y'), Aktion: dropoff, Belohnung: 20\n"
     ]
    }
   ],
   "source": [
    "# Nach der Value Iteration: Policy Extraction mit Q\n",
    "#--------------------------------------------------------------------------------\n",
    "def extract_policy(V, transitions, gamma=0.9):\n",
    "    Q_star = {}\n",
    "    policy = {}\n",
    "    \n",
    "    for state in states:\n",
    "        Q_star[state] = {}\n",
    "        best_value = -float('inf')\n",
    "        best_action = None\n",
    "        \n",
    "        for action in actions:\n",
    "            next_state, reward, done = transitions[state][action]\n",
    "            if done == True:\n",
    "                future_value = 0\n",
    "            else:\n",
    "                future_value = V[next_state]\n",
    "\n",
    "            q_value = reward + gamma * future_value\n",
    "            Q_star[state][action] = q_value\n",
    "            \n",
    "            if q_value > best_value:\n",
    "                best_value = q_value\n",
    "                best_action = action\n",
    "        \n",
    "        policy[state] = best_action\n",
    "    return Q_star, policy\n",
    "\n",
    "sample_state = (2,1, 'B', 'Y')\n",
    "Q_star, policy = extract_policy(V, transitions)\n",
    "\n",
    "Trajektorie = []\n",
    "while True:\n",
    "    action = policy[sample_state]\n",
    "    next_state, reward, done = transitions[sample_state][action]\n",
    "    Trajektorie.append((sample_state, action, reward, next_state))\n",
    "    print(f\"Zustand: {sample_state}, Aktion: {action}, Belohnung: {reward}\")\n",
    "    sample_state = next_state\n",
    "    if done == True:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3b2dc64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.85323"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V[(2,1, 'B', 'Y')]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
